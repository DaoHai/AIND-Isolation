{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A step-by-step guide on building game isolation agent with minimax, iterative deepning and alphabeta pruning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Sample Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1   2   3   4   5   6\n",
      "\r",
      "0  |   |   |   |   |   | 2 |   | \n",
      "\r",
      "1  |   |   |   |   |   |   |   | \n",
      "\r",
      "2  |   |   |   | 1 |   |   |   | \n",
      "\r",
      "3  |   |   |   |   |   |   |   | \n",
      "\r",
      "4  |   |   |   |   |   |   |   | \n",
      "\r",
      "5  |   |   |   |   |   |   |   | \n",
      "\r",
      "6  |   |   |   |   |   |   |   | \n",
      "\r\n",
      "[(1, 5), (3, 5), (4, 4), (0, 2), (0, 4), (4, 2), (1, 1), (3, 1)]\n",
      "\n",
      "Old state:\n",
      "     0   1   2   3   4   5   6\n",
      "\r",
      "0  |   |   |   |   |   | 2 |   | \n",
      "\r",
      "1  |   |   |   |   |   |   |   | \n",
      "\r",
      "2  |   |   |   | 1 |   |   |   | \n",
      "\r",
      "3  |   |   |   |   |   |   |   | \n",
      "\r",
      "4  |   |   |   |   |   |   |   | \n",
      "\r",
      "5  |   |   |   |   |   |   |   | \n",
      "\r",
      "6  |   |   |   |   |   |   |   | \n",
      "\r\n",
      "\n",
      "New state:\n",
      "     0   1   2   3   4   5   6\n",
      "\r",
      "0  |   |   |   |   |   | 2 |   | \n",
      "\r",
      "1  |   | 1 |   |   |   |   |   | \n",
      "\r",
      "2  |   |   |   | - |   |   |   | \n",
      "\r",
      "3  |   |   |   |   |   |   |   | \n",
      "\r",
      "4  |   |   |   |   |   |   |   | \n",
      "\r",
      "5  |   |   |   |   |   |   |   | \n",
      "\r",
      "6  |   |   |   |   |   |   |   | \n",
      "\r\n",
      "\n",
      "Winner: <sample_players.GreedyPlayer object at 0x7f2f007d1668>\n",
      "Outcome: illegal move\n",
      "     0   1   2   3   4   5   6\n",
      "\r",
      "0  |   |   | - |   |   | - |   | \n",
      "\r",
      "1  | - |   | - |   |   |   |   | \n",
      "\r",
      "2  |   |   | - | - | - |   |   | \n",
      "\r",
      "3  |   | - |   | - | - | - |   | \n",
      "\r",
      "4  |   | - | - | - | - |   |   | \n",
      "\r",
      "5  | 1 |   | - |   | - |   | - | \n",
      "\r",
      "6  | - |   | - |   |   | 2 |   | \n",
      "\r\n",
      "Move history:\n",
      "[[0, 2], [2, 4], [1, 0], [4, 3], [3, 1], [2, 2], [1, 2], [3, 4], [3, 3], [4, 2], [5, 2], [5, 4], [6, 0], [3, 5], [4, 1], [5, 6], [6, 2], [4, 4], [5, 0], [6, 5]]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # from isolation.py get the Board class\n",
    "    from isolation import Board\n",
    "    from sample_players import *\n",
    "\n",
    "    ## Setup\n",
    "    # create an isolation board (by default 7x7) and some players\n",
    "    player1 = RandomPlayer()\n",
    "    player2 = GreedyPlayer()\n",
    "    game = Board(player1, player2)\n",
    "\n",
    "    # place player 1 on the board at row 2, column 3, then place player 2 on\n",
    "    # the board at row 0, column 5; display the resulting board state.  Note\n",
    "    # that .apply_move() changes the calling object\n",
    "    \n",
    "    # apply move and print the game board\n",
    "    game.apply_move((2, 3))\n",
    "    game.apply_move((0, 5))\n",
    "    print(game.to_string())\n",
    "    \n",
    "    ## Play\n",
    "    \n",
    "    # players take turns moving on the board, so player1 should be next to move\n",
    "    assert(player1 == game.active_player)\n",
    "\n",
    "    # get a list of the legal moves available to the active player\n",
    "    print(game.get_legal_moves())\n",
    "\n",
    "    # get a successor of the current state by making a copy of the board and\n",
    "    # applying a move. Notice that this does NOT change the calling object\n",
    "    # (unlike .apply_move()).\n",
    "    \n",
    "    # make a new board as a branch of the old board, and assert not the same as before, then print both \n",
    "    new_game = game.forecast_move((1, 1))\n",
    "    assert(new_game.to_string() != game.to_string())\n",
    "    print(\"\\nOld state:\\n{}\".format(game.to_string()))\n",
    "    print(\"\\nNew state:\\n{}\".format(new_game.to_string()))\n",
    "\n",
    "    # play the remainder of the game automatically -- outcome can be \"illegal\n",
    "    # move\" or \"timeout\"; it should _always_ be \"illegal move\" in this example\n",
    "    \n",
    "    # play the game, and get the winner, history, and outcome from \n",
    "    winner, history, outcome = game.play()\n",
    "    print(\"\\nWinner: {}\\nOutcome: {}\".format(winner, outcome))\n",
    "    print(game.to_string())\n",
    "    print(\"Move history:\\n{!s}\".format(history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our game agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SearchTimeout(Exception):\n",
    "    \"\"\"Subclass base exception for code clarity. \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def custom_score(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    This should be the best heuristic function for your project submission.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "    if game.is_loser(player):\n",
    "        return -math.inf\n",
    "    if game.is_winner(player):\n",
    "        return math.inf\n",
    "    \n",
    "    player_moves = len(game.get_legal_moves(player))\n",
    "    opponent_moves = len(game.get_legal_moves(game.get_opponent(player)))\n",
    "    blank_spaces = game.get_blank_spaces()\n",
    "    percent_board_occupied = int((len(blank_spaces)/(game.width * game.height)) * 100)\n",
    "    \n",
    "    if percent_board_occupied < 30 :\n",
    "        return float(player_moves - 2*opponent_moves)\n",
    "    else:\n",
    "        return float(2*player_moves - opponent_moves)\n",
    "    \n",
    "\n",
    "    # list of locations that fall onto the walls of board \n",
    "#    walls = [\n",
    "#        [(0, i) for i in range(game.width)],\n",
    "#        [(i, 0) for i in range(game.height)],\n",
    "#        [(game.width - 1, i) for i in range(game.width)],\n",
    "#        [(i, game.height - 1) for i in range(game.height)]\n",
    "#    ]\n",
    "#\n",
    "#    # list of corner locations of the board  \n",
    "#    corners = [(0,0), (0,game.width-1), (game.height-1,0), (game.height-1,game.width-1)]\n",
    "#    \n",
    "#    \n",
    "#\n",
    "#    player_moves = len(game.get_legal_moves(player))\n",
    "#    opponent_moves = len(game.get_legal_moves(game.get_opponent(player)))\n",
    "#    \n",
    "#    moves_wall = []\n",
    "#    moves_corner = []\n",
    "#    for move in game.get_legal_moves(player):\n",
    "#        if move in walls:\n",
    "#           moves_wall.append(move)\n",
    "#        elif move in corners:\n",
    "#           moves_corner.append(move)\n",
    "#           \n",
    "#    moves_wall_corner = len(moves_wall) + len(moves_corner)\n",
    "#    better_moves= player_moves - moves_wall_corner\n",
    "#    \n",
    "#    \n",
    "\n",
    "def custom_score_2(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "    if game.is_loser(player):\n",
    "        return -math.inf\n",
    "    if game.is_winner(player):\n",
    "        return math.inf\n",
    "\n",
    "    player_moves = len(game.get_legal_moves(player))\n",
    "    opponent_moves = len(game.get_legal_moves(game.get_opponent(player)))\n",
    "    return float(2*player_moves-opponent_moves)\n",
    "\n",
    "def custom_score_3(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "    if game.is_loser(player):\n",
    "        return -math.inf\n",
    "    if game.is_winner(player):\n",
    "        return math.inf\n",
    "\n",
    "    player_moves = len(game.get_legal_moves(player))\n",
    "    opponent_moves = len(game.get_legal_moves(game.get_opponent(player)))\n",
    "    return float(player_moves-2*opponent_moves)\n",
    "\n",
    "\n",
    "\n",
    "class IsolationPlayer:\n",
    "    \"\"\"Base class for minimax and alphabeta agents -- this class is never\n",
    "    constructed or tested directly.\n",
    "    ********************  DO NOT MODIFY THIS CLASS  ********************\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_depth : int (optional)\n",
    "        A strictly positive integer (i.e., 1, 2, 3,...) for the number of\n",
    "        layers in the game tree to explore for fixed-depth search. (i.e., a\n",
    "        depth of one (1) would only explore the immediate sucessors of the\n",
    "        current state.)\n",
    "    score_fn : callable (optional)\n",
    "        A function to use for heuristic evaluation of game states.\n",
    "    timeout : float (optional)\n",
    "        Time remaining (in milliseconds) when search is aborted. Should be a\n",
    "        positive value large enough to allow the function to return before the\n",
    "        timer expires.\n",
    "    \"\"\"\n",
    "    def __init__(self, search_depth=30, score_fn=custom_score, timeout=35.):\n",
    "        self.search_depth = search_depth\n",
    "        self.score = score_fn\n",
    "        self.time_left = None\n",
    "        self.TIMER_THRESHOLD = timeout\n",
    "\n",
    "\n",
    "class MinimaxPlayer(IsolationPlayer):\n",
    "    \"\"\"Game-playing agent that chooses a move using depth-limited minimax\n",
    "    search. You must finish and test this player to make sure it properly uses\n",
    "    minimax to return a good move before the search time limit expires.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def isTimeout(self):\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "           raise SearchTimeout()\n",
    "\n",
    "    def get_move(self, game, time_left):\n",
    "        \"\"\"Search for the best move from the available legal moves and return a\n",
    "        result before the time limit expires.\n",
    "        **************  YOU DO NOT NEED TO MODIFY THIS FUNCTION  *************\n",
    "        For fixed-depth search, this function simply wraps the call to the\n",
    "        minimax method, but this method provides a common interface for all\n",
    "        Isolation agents, and you will replace it in the AlphaBetaPlayer with\n",
    "        iterative deepening search.\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : `isolation.Board`\n",
    "            An instance of `isolation.Board` encoding the current state of the\n",
    "            game (e.g., player locations and blocked cells).\n",
    "        time_left : callable\n",
    "            A function that returns the number of milliseconds left in the\n",
    "            current turn. Returning with any less than 0 ms remaining forfeits\n",
    "            the game.\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            Board coordinates corresponding to a legal move; may return\n",
    "            (-1, -1) if there are no available legal moves.\n",
    "        \"\"\"\n",
    "        self.time_left = time_left\n",
    "\n",
    "\n",
    "\n",
    "        # Initialize the best move so that this function returns something\n",
    "        # in case the search fails due to timeout\n",
    "        best_move = (-1, -1)\n",
    "\n",
    "        try:\n",
    "            # The try/except block will automatically catch the exception\n",
    "            # raised when the timer is about to expire.\n",
    "            return self.minimax(game, self.search_depth)\n",
    "\n",
    "        except SearchTimeout:\n",
    "            pass  # Handle any actions required after timeout as needed\n",
    "\n",
    "        # Return the best move from the last completed search iteration\n",
    "        return best_move\n",
    "\n",
    "\n",
    "    def maxvalue(self, game, max_depth, curr_depth):\n",
    "        \"\"\"\n",
    "        Search for the branch with the highest score value.  Return that value.\n",
    "        Parameters\n",
    "        ---------------\n",
    "        game : `isolation.Board`\n",
    "            An instance of `isolation.Board` encoding the current state of the\n",
    "            game (e.g., player locations and blocked cells).\n",
    "        max_depth: int\n",
    "            The maximum number of plies to check (this remains the same for\n",
    "            Minimax, and will increase on each run in the AlphaBetaPlayer \n",
    "            which uses iterative deepening)\n",
    "        curr_depth: int\n",
    "            The current depth being checked (incremented on each call until it reaches\n",
    "            max_depth)\n",
    "        Returns\n",
    "        -----------------\n",
    "        val : int\n",
    "            The score for the best move available (the maximum given all the legal moves available)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "           raise SearchTimeout()\n",
    "\n",
    "        # Reached the depth we wanted to consider. Return the score for that\n",
    "        #   move (based on the heuristics in improved_score, or custom_score)\n",
    "        if (max_depth==curr_depth):\n",
    "            return self.score(game, self)\n",
    "        else:\n",
    "\n",
    "            # Increase depth counter for when we next call minvalue\n",
    "            curr_depth+=1\n",
    "            moves = game.get_legal_moves(self)\n",
    "            if len(moves)==0:\n",
    "                # No legals moves left, player would lose if we chose this branch\n",
    "                return float(\"-inf\")\n",
    "\n",
    "            best_move = moves[0]\n",
    "            maxv=float(\"-inf\")\n",
    "\n",
    "            # Consider each move. If it returns a higher predicted value than\n",
    "            #   what was previously stored in best_move, replace best_move and maxv\n",
    "            for m in moves:\n",
    "                val = self.minvalue(game.forecast_move(m), max_depth, curr_depth)\n",
    "                if (val>maxv):\n",
    "                    maxv = val\n",
    "                    best_move = m    \n",
    "            return maxv\n",
    "\n",
    "    \n",
    "\n",
    "    def minvalue(self, game, max_depth, curr_depth):\n",
    "        \"\"\"\n",
    "        Search for the branch with the highest score value.  Return that value.\n",
    "        Parameters\n",
    "        ---------------\n",
    "        game : `isolation.Board`\n",
    "            An instance of `isolation.Board` encoding the current state of the\n",
    "            game (e.g., player locations and blocked cells).\n",
    "        max_depth: int\n",
    "            The maximum number of plies to check (this remains the same for\n",
    "            Minimax, and will increase on each run in the AlphaBetaPlayer \n",
    "            which uses iterative deepening)\n",
    "        curr_depth: int\n",
    "            The current depth being checked (incremented on each call until it reaches\n",
    "            max_depth)\n",
    "        Returns\n",
    "        -----------------\n",
    "        val : int\n",
    "            The score for the best move available (the maximum given all the legal moves available)\n",
    "        \"\"\"\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "\n",
    "        # Reached the depth we wanted to consider. Return the score for that\n",
    "        #   move (based on the heuristics in improved_score, or custom_score)\n",
    "        if (max_depth==curr_depth):\n",
    "            return self.score(game, self)\n",
    "        else:\n",
    "            # Increase depth counter for when we next call maxvalue\n",
    "            curr_depth+=1\n",
    "\n",
    "            moves = game.get_legal_moves()\n",
    "            if len(moves)==0:\n",
    "                #no legal moves left for opponent, opponent would lose on this branch\n",
    "                return float(\"+inf\")\n",
    "\n",
    "            best_move = moves[0]\n",
    "            minv=float(\"inf\")\n",
    "\n",
    "            # Consider each move. If it returns a lower predicted value than\n",
    "            #   what was previously stored in best_move, replace best_move and minv            \n",
    "            for m in moves:\n",
    "                val = self.maxvalue(game.forecast_move(m), max_depth, curr_depth)\n",
    "                if (val<minv):\n",
    "                    minv = val\n",
    "                    best_move = m     \n",
    "            return minv\n",
    "\n",
    "\n",
    "\n",
    "    def minimax(self, game, depth):\n",
    "        \"\"\"Implement depth-limited minimax search algorithm as described in\n",
    "        the lectures.\n",
    "        This should be a modified version of MINIMAX-DECISION in the AIMA text.\n",
    "        https://github.com/aimacode/aima-pseudocode/blob/master/md/Minimax-Decision.md\n",
    "        **********************************************************************\n",
    "            You MAY add additional methods to this class, or define helper\n",
    "                 functions to implement the required functionality.\n",
    "        **********************************************************************\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : isolation.Board\n",
    "            An instance of the Isolation game `Board` class representing the\n",
    "            current game state\n",
    "        depth : int\n",
    "            Depth is an integer representing the maximum number of plies to\n",
    "            search in the game tree before aborting\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            The board coordinates of the best move found in the current search;\n",
    "            (-1, -1) if there are no legal moves\n",
    "        Notes\n",
    "        -----\n",
    "            (1) You MUST use the `self.score()` method for board evaluation\n",
    "                to pass the project tests; you cannot call any other evaluation\n",
    "                function directly.\n",
    "            (2) If you use any helper functions (e.g., as shown in the AIMA\n",
    "                pseudocode) then you must copy the timer check into the top of\n",
    "                each helper function or else your agent will timeout during\n",
    "                testing.\n",
    "        \"\"\"\n",
    "\n",
    "  \n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "\n",
    "\n",
    "        moves = game.get_legal_moves()\n",
    "\n",
    "        if len(moves)==0:\n",
    "            best_move = (-1, -1)   # no moves left, forfeit game\n",
    "\n",
    "        else:              \n",
    "            best_move = moves[0]\n",
    "            maxval=float(\"-inf\")\n",
    "\n",
    "            # We're not doing iterative deepening, so we put the try/except around \n",
    "            #  testing each move. If we run out of time, we return the best move that\n",
    "            #  we've found so far.\n",
    "\n",
    "            for m in moves:\n",
    "                try:\n",
    "                    val = self.minvalue(game.forecast_move(m), depth, 1)\n",
    "            \n",
    "                except SearchTimeout:\n",
    "                    return best_move\n",
    "                \n",
    "                if val>maxval:\n",
    "                    maxval = val\n",
    "                    best_move = m    \n",
    "\n",
    "\n",
    "        return best_move\n",
    "\n",
    "\n",
    "\n",
    "class AlphaBetaPlayer(IsolationPlayer):\n",
    "    \"\"\"Game-playing agent that chooses a move using iterative deepening minimax\n",
    "    search with alpha-beta pruning. You must finish and test this player to\n",
    "    make sure it returns a good move before the search time limit expires.\n",
    "    \"\"\"\n",
    "\n",
    "    def isTimeout(self):\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "           raise SearchTimeout()\n",
    "\n",
    "    def get_move(self, game, time_left):\n",
    "        \"\"\"Search for the best move from the available legal moves and return a\n",
    "        result before the time limit expires.\n",
    "        Modify the get_move() method from the MinimaxPlayer class to implement\n",
    "        iterative deepening search instead of fixed-depth search.\n",
    "        **********************************************************************\n",
    "        NOTE: If time_left() < 0 when this function returns, the agent will\n",
    "              forfeit the game due to timeout. You must return _before_ the\n",
    "              timer reaches 0.\n",
    "        **********************************************************************\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : `isolation.Board`\n",
    "            An instance of `isolation.Board` encoding the current state of the\n",
    "            game (e.g., player locations and blocked cells).\n",
    "        time_left : callable\n",
    "            A function that returns the number of milliseconds left in the\n",
    "            current turn. Returning with any less than 0 ms remaining forfeits\n",
    "            the game.\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            Board coordinates corresponding to a legal move; may return\n",
    "            (-1, -1) if there are no available legal moves.\n",
    "        \"\"\"\n",
    "        self.time_left = time_left\n",
    "\n",
    "\n",
    "       # Initialize the best move so that this function returns something\n",
    "        # in case the search fails due to timeout\n",
    "        best_move = (-1, -1)\n",
    "        depth = 1\n",
    "\n",
    "        # Test if first move of the game -- if so pick the center square\n",
    "        if len(game.get_blank_spaces()) == game.width * game.height:\n",
    "            return (3,3)\n",
    "\n",
    "\n",
    "        while depth <= self.search_depth:   \n",
    "            try:\n",
    "            # The try/except block will automatically catch the exception\n",
    "            # raised when the timer is about to expire.\n",
    "                best_move = self.alphabeta(game, depth)\n",
    "                depth+=1\n",
    "\n",
    "            except SearchTimeout:\n",
    "#                print(\"Timeout- spaces remaining: \", len(game.get_blank_spaces()))\n",
    "                return best_move\n",
    "\n",
    "\n",
    "#        print(\"Spaces remaining: \", len(game.get_blank_spaces()))\n",
    "        # Return the best move from the last completed search iteration\n",
    "        return best_move\n",
    "\n",
    "\n",
    "\n",
    "    def maxvalue(self, game, alpha, beta, max_depth, curr_depth):\n",
    "        \"\"\"\n",
    "        Search for the branch with the highest score value.  Return that value.\n",
    "        Parameters\n",
    "        ---------------\n",
    "        game : `isolation.Board`\n",
    "            An instance of `isolation.Board` encoding the current state of the\n",
    "            game (e.g., player locations and blocked cells).\n",
    "        alpha : float\n",
    "            The low end of alpha-beta pruning -- while you are in minvalue() function,\n",
    "            if minv is lower than this, you know this branch won't get considered in the\n",
    "            maxvalue node above it, so you can stop testing\n",
    "            \n",
    "        beta : float\n",
    "            The high end of alpha-beta pruning -- while you are in maxvalue() function, \n",
    "            if maxv is higher than this, you know this branch won't get considered in the \n",
    "            minvalue node above it, so you can stop testing \n",
    "        max_depth: int\n",
    "            The maximum number of plies to check (this remains the same for\n",
    "            Minimax, and will increase on each run in the AlphaBetaPlayer \n",
    "            which uses iterative deepening)\n",
    "        curr_depth: int\n",
    "            The current depth being checked (incremented on each call until it reaches\n",
    "            max_depth)\n",
    "        Returns\n",
    "        -----------------\n",
    "        val : float\n",
    "            The score for the best move available (the maximum given all the legal moves available)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "           raise SearchTimeout()\n",
    "\n",
    "\n",
    "        # Reached the depth we wanted to consider. Return the score for that\n",
    "        #   move (based on the heuristics in improved_score, or custom_score)\n",
    "        if (max_depth==curr_depth):\n",
    "            return self.score(game, self)\n",
    "\n",
    "        else:\n",
    "            # Increase depth counter for when we next call minvalue\n",
    "            curr_depth+=1\n",
    "            moves = game.get_legal_moves(self)\n",
    "            if len(moves)==0:\n",
    "                # No legals moves left\n",
    "                return float(\"-inf\")\n",
    "            \n",
    "            maxv = float(\"-inf\")\n",
    "\n",
    "            # Consider each move. If it returns a higher predicted value than\n",
    "            #   what was previously stored in best_move, replace maxv\n",
    "\n",
    "            for m in moves:\n",
    "                val = self.minvalue(game.forecast_move(m), alpha, beta, max_depth, curr_depth)\n",
    "                if val>maxv:\n",
    "                    maxv = val\n",
    "\n",
    "                # Check if maxv is more than beta - this means it is more than a neighboring node, and the\n",
    "                # minvalue above will never choose this branch. You can stop searching this branch and \n",
    "                # return upwards.\n",
    "                if maxv >= beta:\n",
    "                    return maxv\n",
    "\n",
    "                # Need to continue searching this branch. If maxv is higher than the previously saved alpha,\n",
    "                #  set alpha to be equal to this new max\n",
    "                else:\n",
    "                    alpha = max(alpha, maxv) \n",
    "\n",
    "            return maxv\n",
    "\n",
    "\n",
    "    def minvalue(self, game, alpha, beta, max_depth, curr_depth):\n",
    "        \"\"\"\n",
    "        Search for the branch with the highest score value.  Return that value.\n",
    "        Parameters\n",
    "        ---------------\n",
    "        game : `isolation.Board`\n",
    "            An instance of `isolation.Board` encoding the current state of the\n",
    "            game (e.g., player locations and blocked cells).\n",
    "        alpha : float\n",
    "            The low end of alpha-beta pruning -- while you are in minvalue() function,\n",
    "            if minv is lower than this, you know this branch won't get considered in the\n",
    "            maxvalue node above it, so you can stop testing\n",
    "            \n",
    "        beta : float\n",
    "            The high end of alpha-beta pruning -- while you are in maxvalue() function, \n",
    "            if maxv is higher than this, you know this branch won't get considered in the \n",
    "            minvalue node above it, so you can stop testing \n",
    "        max_depth: int\n",
    "            The maximum number of plies to check (this remains the same for\n",
    "            Minimax, and will increase on each run in the AlphaBetaPlayer \n",
    "            which uses iterative deepening)\n",
    "        curr_depth: int\n",
    "            The current depth being checked (incremented on each call until it reaches\n",
    "            max_depth)\n",
    "        Returns\n",
    "        -----------------\n",
    "        val : float\n",
    "            The score for the best move available (the maximum given all the legal moves available)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "\n",
    "        # Reached the depth we wanted to consider. Return the score for that\n",
    "        #   move (based on the heuristics in improved_score, or custom_score)\n",
    "        if (max_depth==curr_depth):\n",
    "            return self.score(game, self)\n",
    "        else:\n",
    "            # Increase depth counter for when we next call maxvalue\n",
    "            curr_depth+=1\n",
    "\n",
    "            moves = game.get_legal_moves()\n",
    "            if len(moves)==0:\n",
    "                #no legal moves left for opponent, opponent would lose on this branch\n",
    "                return float(\"+inf\")\n",
    "\n",
    "            minv = float(\"inf\")\n",
    "\n",
    "            # Consider each move. If a given move returns a lower predicted value than\n",
    "            #   what was previously found, replace minv\n",
    "            for m in moves:\n",
    "                val = self.maxvalue(game.forecast_move(m), alpha, beta, max_depth, curr_depth)\n",
    "                if val < minv:\n",
    "                    minv = val\n",
    "\n",
    "                # Check if minv is less than alpha - this means it is less than a neighboring node, and the\n",
    "                # maxvalue above will never choose this branch. You can stop searching this branch and \n",
    "                # return upwards.\n",
    "                if minv <= alpha:\n",
    "                    return minv\n",
    "\n",
    "                # Need to continue searching this branch. If minv is lower than the previously saved beta,\n",
    "                #  set beta to be equal to this new min\n",
    "                else:\n",
    "                    beta = min(beta, minv)\n",
    "            return minv\n",
    "\n",
    "\n",
    "    def alphabeta(self, game, depth, alpha=float(\"-inf\"), beta=float(\"inf\")):\n",
    "        \"\"\"Implement depth-limited minimax search with alpha-beta pruning as\n",
    "        described in the lectures.\n",
    "        This should be a modified version of ALPHA-BETA-SEARCH in the AIMA text\n",
    "        https://github.com/aimacode/aima-pseudocode/blob/master/md/Alpha-Beta-Search.md\n",
    "        **********************************************************************\n",
    "            You MAY add additional methods to this class, or define helper\n",
    "                 functions to implement the required functionality.\n",
    "        **********************************************************************\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : isolation.Board\n",
    "            An instance of the Isolation game `Board` class representing the\n",
    "            current game state\n",
    "        depth : int\n",
    "            Depth is an integer representing the maximum number of plies to\n",
    "            search in the game tree before aborting\n",
    "        alpha : float\n",
    "            Alpha limits the lower bound of search on minimizing layers\n",
    "        beta : float\n",
    "            Beta limits the upper bound of search on maximizing layers\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            The board coordinates of the best move found in the current search;\n",
    "            (-1, -1) if there are no legal moves\n",
    "        Notes\n",
    "        -----\n",
    "            (1) You MUST use the `self.score()` method for board evaluation\n",
    "                to pass the project tests; you cannot call any other evaluation\n",
    "                function directly.\n",
    "            (2) If you use any helper functions (e.g., as shown in the AIMA\n",
    "                pseudocode) then you must copy the timer check into the top of\n",
    "                each helper function or else your agent will timeout during\n",
    "                testing.\n",
    "        \"\"\"\n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "\n",
    "\n",
    "        moves = game.get_legal_moves()\n",
    "        if len(moves)==0:    # no legal moves available, forfeit the game\n",
    "            return (-1, -1)\n",
    "             \n",
    "        best_move = moves[0]\n",
    "        maxval=float(\"-inf\")\n",
    "\n",
    "        # Consider each available move, and select the move with the highest\n",
    "        #   score (returned from searching the tree \"depth\" nodes down)\n",
    "        #   Each time this alphabeta() function is called, depth will be one\n",
    "        #   higher, and the search will be that much deeper\n",
    "\n",
    "        for m in moves:\n",
    "            val = self.minvalue(game.forecast_move(m), alpha, beta, depth, 1)\n",
    "                \n",
    "            if val>maxval:\n",
    "                maxval = val\n",
    "                best_move = m    \n",
    "\n",
    "            # Increase alpha to the max value already found - this way minvalue() \n",
    "            #  can stop searching if it knows it will return a value lower than\n",
    "            #  a max that was already found\n",
    "            alpha = max(alpha, maxval)\n",
    "\n",
    "        return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tournament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This script evaluates the performance of the custom_score evaluation\n",
      "function against a baseline agent using alpha-beta search and iterative\n",
      "deepening (ID) called `AB_Improved`. The three `AB_Custom` agents use\n",
      "ID and alpha-beta search with the custom_score functions defined in\n",
      "game_agent.py.\n",
      "\n",
      "                        *************************                         \n",
      "                             Playing Matches                              \n",
      "                        *************************                         \n",
      "\n",
      " Match #   Opponent    AB_Improved   AB_Custom   AB_Custom_2  AB_Custom_3 \n",
      "                        Won | Lost   Won | Lost   Won | Lost   Won | Lost \n",
      "    1       Random      19  |   1    19  |   1    20  |   0    20  |   0  \n",
      "    2       MM_Open     14  |   6    13  |   7    18  |   2    17  |   3  \n",
      "    3      MM_Center    16  |   4    13  |   7    13  |   7    13  |   7  \n",
      "    4     MM_Improved   17  |   3    17  |   3    15  |   5    14  |   6  \n",
      "    5       AB_Open     10  |  10    13  |   7    15  |   5     8  |  12  \n",
      "    6      AB_Center    12  |   8    10  |  10    10  |  10    12  |   8  \n",
      "    7     AB_Improved    9  |  11    10  |  10    11  |   9     8  |  12  \n",
      "--------------------------------------------------------------------------\n",
      "           Win Rate:      69.3%        67.9%        72.9%        65.7%    \n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from isolation import Board\n",
    "from sample_players import (RandomPlayer, open_move_score,\n",
    "                            improved_score, center_score)\n",
    "from game_agent import (MinimaxPlayer, AlphaBetaPlayer, custom_score,\n",
    "                        custom_score_2, custom_score_3)\n",
    "\n",
    "NUM_MATCHES = 10  # number of matches against each opponent\n",
    "TIME_LIMIT = 100  # number of milliseconds before timeout\n",
    "\n",
    "DESCRIPTION = \"\"\"\n",
    "This script evaluates the performance of the custom_score evaluation\n",
    "function against a baseline agent using alpha-beta search and iterative\n",
    "deepening (ID) called `AB_Improved`. The three `AB_Custom` agents use\n",
    "ID and alpha-beta search with the custom_score functions defined in\n",
    "game_agent.py.\n",
    "\"\"\"\n",
    "\n",
    "Agent = namedtuple(\"Agent\", [\"player\", \"name\"])\n",
    "\n",
    "\n",
    "def play_round(cpu_agent, test_agents, win_counts, num_matches):\n",
    "    \"\"\"Compare the test agents to the cpu agent in \"fair\" matches.\n",
    "\n",
    "    \"Fair\" matches use random starting locations and force the agents to\n",
    "    play as both first and second player to control for advantages resulting\n",
    "    from choosing better opening moves or having first initiative to move.\n",
    "    \"\"\"\n",
    "    timeout_count = 0\n",
    "    forfeit_count = 0\n",
    "    for _ in range(num_matches):\n",
    "\n",
    "        games = sum([[Board(cpu_agent.player, agent.player),\n",
    "                      Board(agent.player, cpu_agent.player)]\n",
    "                    for agent in test_agents], [])\n",
    "\n",
    "        # initialize all games with a random move and response\n",
    "        for _ in range(2):\n",
    "            move = random.choice(games[0].get_legal_moves())\n",
    "            for game in games:\n",
    "                game.apply_move(move)\n",
    "\n",
    "        # play all games and tally the results\n",
    "        for game in games:\n",
    "            winner, _, termination = game.play(time_limit=TIME_LIMIT)\n",
    "            win_counts[winner] += 1\n",
    "\n",
    "            if termination == \"timeout\":\n",
    "                timeout_count += 1\n",
    "            elif termination == \"forfeit\":\n",
    "                forfeit_count += 1\n",
    "\n",
    "    return timeout_count, forfeit_count\n",
    "\n",
    "\n",
    "def update(total_wins, wins):\n",
    "    for player in total_wins:\n",
    "        total_wins[player] += wins[player]\n",
    "    return total_wins\n",
    "\n",
    "\n",
    "def play_matches(cpu_agents, test_agents, num_matches):\n",
    "    \"\"\"Play matches between the test agent and each cpu_agent individually. \"\"\"\n",
    "    total_wins = {agent.player: 0 for agent in test_agents}\n",
    "    total_timeouts = 0.\n",
    "    total_forfeits = 0.\n",
    "    total_matches = 2 * num_matches * len(cpu_agents)\n",
    "\n",
    "    print(\"\\n{:^9}{:^13}\".format(\"Match #\", \"Opponent\") + ''.join(['{:^13}'.format(x[1].name) for x in enumerate(test_agents)]))\n",
    "    print(\"{:^9}{:^13} \".format(\"\", \"\") +  ' '.join(['{:^5}| {:^5}'.format(\"Won\", \"Lost\") for x in enumerate(test_agents)]))\n",
    "\n",
    "    for idx, agent in enumerate(cpu_agents):\n",
    "        wins = {key: 0 for (key, value) in test_agents}\n",
    "        wins[agent.player] = 0\n",
    "\n",
    "        print(\"{!s:^9}{:^13}\".format(idx + 1, agent.name), end=\"\", flush=True)\n",
    "\n",
    "        counts = play_round(agent, test_agents, wins, num_matches)\n",
    "        total_timeouts += counts[0]\n",
    "        total_forfeits += counts[1]\n",
    "        total_wins = update(total_wins, wins)\n",
    "        _total = 2 * num_matches\n",
    "        round_totals = sum([[wins[agent.player], _total - wins[agent.player]]\n",
    "                            for agent in test_agents], [])\n",
    "        print(' ' + ' '.join([\n",
    "            '{:^5}| {:^5}'.format(\n",
    "                round_totals[i],round_totals[i+1]\n",
    "            ) for i in range(0, len(round_totals), 2)\n",
    "        ]))\n",
    "\n",
    "    print(\"-\" * 74)\n",
    "    print('{:^9}{:^13}'.format(\"\", \"Win Rate:\") +\n",
    "        ''.join([\n",
    "            '{:^13}'.format(\n",
    "                \"{:.1f}%\".format(100 * total_wins[x[1].player] / total_matches)\n",
    "            ) for x in enumerate(test_agents)\n",
    "    ]))\n",
    "\n",
    "    if total_timeouts:\n",
    "        print((\"\\nThere were {} timeouts during the tournament -- make sure \" +\n",
    "               \"your agent handles search timeout correctly, and consider \" +\n",
    "               \"increasing the timeout margin for your agent.\\n\").format(\n",
    "            total_timeouts))\n",
    "    if total_forfeits:\n",
    "        print((\"\\nYour ID search forfeited {} games while there were still \" +\n",
    "               \"legal moves available to play.\\n\").format(total_forfeits))\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Define two agents to compare -- these agents will play from the same\n",
    "    # starting position against the same adversaries in the tournament\n",
    "    test_agents = [\n",
    "        Agent(AlphaBetaPlayer(score_fn=improved_score), \"AB_Improved\"),\n",
    "        Agent(AlphaBetaPlayer(score_fn=custom_score), \"AB_Custom\"),\n",
    "        Agent(AlphaBetaPlayer(score_fn=custom_score_2), \"AB_Custom_2\"),\n",
    "        Agent(AlphaBetaPlayer(score_fn=custom_score_3), \"AB_Custom_3\")\n",
    "    ]\n",
    "\n",
    "    # Define a collection of agents to compete against the test agents\n",
    "    cpu_agents = [\n",
    "        Agent(RandomPlayer(), \"Random\"),\n",
    "        Agent(MinimaxPlayer(score_fn=open_move_score), \"MM_Open\"),\n",
    "        Agent(MinimaxPlayer(score_fn=center_score), \"MM_Center\"),\n",
    "        Agent(MinimaxPlayer(score_fn=improved_score), \"MM_Improved\"),\n",
    "        Agent(AlphaBetaPlayer(score_fn=open_move_score), \"AB_Open\"),\n",
    "        Agent(AlphaBetaPlayer(score_fn=center_score), \"AB_Center\"),\n",
    "        Agent(AlphaBetaPlayer(score_fn=improved_score), \"AB_Improved\")\n",
    "    ]\n",
    "\n",
    "    print(DESCRIPTION)\n",
    "    print(\"{:^74}\".format(\"*************************\"))\n",
    "    print(\"{:^74}\".format(\"Playing Matches\"))\n",
    "    print(\"{:^74}\".format(\"*************************\"))\n",
    "    play_matches(cpu_agents, test_agents, NUM_MATCHES)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
